{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mahTizW0jeDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiểu rõ về bộ dữ liệu (Predict Health Outcomes of Horses Dataset)"
      ],
      "metadata": {
        "id": "pCHBpcn5jBb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mục tiêu hoặc Mục tiêu của Dự án:\n",
        "Với các chỉ số y tế khác nhau của ngựa, chúng ta sẽ dự đoán kết quả sức khỏe của ngựa dựa trên các chỉ số đã cho.\n",
        "- Sự đánh giá:\n",
        "Các bài gửi được đánh giá dựa trên Điểm F1 trung bình vi mô giữa giá trị dự đoán và giá trị thực tế.\n",
        "- Tập dữ liệu cho cuộc thi này là tập dữ liệu tổng hợp dựa trên Bộ dữ liệu sinh tồn của ngựa. Như chúng ta có thể đọc trong phần mô tả tập dữ liệu ban đầu, nhiệm vụ chính của tập dữ liệu là hiểu dữ liệu và đánh giá xem một con ngựa có thể sống sót hay không dựa trên tình trạng bệnh lý. Tập dữ liệu gốc có nhiều giá trị bị thiếu và theo tác giả, vấn đề này thực sự là một vấn đề ở đó. Hơn nữa, tất cả các chỉ số đều được chuyển đổi thành từ để dễ dàng hiểu được chúng thể hiện điều gì."
      ],
      "metadata": {
        "id": "qcTbY0swjhrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tập dữ liệu được chia thành 27 đặc điểm chính và mục tiêu. Như chúng ta có thể đọc trong phần mô tả tập dữ liệu gốc, đây là:"
      ],
      "metadata": {
        "id": "di1hhCcaoX7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Phẫu thuật (Surgery): Cho biết liệu con ngựa đã được phẫu thuật hay không.\n",
        "- Tuổi (Age): Tuổi của con ngựa (trẻ em có nghĩa là dưới 6 tháng tuổi).\n",
        "- Số Bệnh Viện (Hospital Number): Số lưu trữ được gán cho con ngựa (có thể không duy nhất nếu con ngựa được điều trị nhiều hơn 1 lần).\n",
        "- Nhiệt độ Hậu môn (Rectal Temperature): Nhiệt độ bình thường là 37.8 độ Celsius và thường sẽ thay đổi khi vấn đề tiến triển. Ban đầu có thể bình thường, sau đó trở nên tăng cao do tổn thương, đi qua lại khoảng bình thường khi con ngựa gặp sốc.\n",
        "- Nhịp Tim (Pulse): Nhịp tim theo đơn vị số nhịp mỗi phút. Đây phản ánh tình trạng tim: 30-40 là bình thường cho ngựa trưởng thành. Rất hiếm khi có nhịp tim thấp hơn bình thường, mặc dù các ngựa thể thao có thể có nhịp tim 20-25. Động vật có tổn thương đau hoặc đang gặp sốc tuần hoàn có thể có nhịp tim tăng cao.\n",
        "- Tần số Hô Hấp (Respiratory Rate): Tần số hô hấp bình thường là 8 đến 10 và tính hữu ích có thể bị nghi ngờ do sự dao động lớn.\n",
        "- Nhiệt độ Các Chi (Temperature of Extremities): Một chỉ báo chủ quan về tuần hoàn ngoại vi. Các chi lạnh hoặc mát có thể chỉ ra nguy cơ sốc, trong khi các chi nóng nên tương quan với nhiệt độ hậu môn tăng cao.\n",
        "- Mạch Ngoại vi (Peripheral Pulse): Chủ quan. Giá trị bình thường hoặc tăng cho thấy tuần hoàn đủ, trong khi giảm hoặc vắng chỉ ra tuần hoàn kém.\n",
        "- Niêm mạc (Mucous Membrane): Một đo lường chủ quan về màu sắc. Màu hồng và hồng sáng có thể chỉ ra tuần hoàn bình thường hoặc hơi tăng. Màu hồng nhạt có thể xuất hiện ở giai đoạn sớm của sốc. Màu xanh nhạt và xanh đậm chỉ ra sự suy giảm nghiêm trọng về tuần hoàn. Đỏ sáng hơn nhiều chỉ ra nhiễm trùng máu.\n",
        "- Thời gian nạp máu cấp tốc (Capillary Refill Time): Một đánh giá lâm sàng. Thời gian nạp càng lâu, tuần hoàn càng kém.\n",
        "- Đau (Pain): Một đánh giá chủ quan về mức độ đau của con ngựa. Nói chung, đau càng nhiều, khả năng cần phẫu thuật càng cao, nhưng không nên coi nó như một biến số có thứ tự hoặc rời rạc.\n",
        "- Hệ tiêu hóa (Peristalsis): Một chỉ báo về hoạt động trong ruột của con ngựa. Khi ruột trở nên phình to hơn hoặc con ngựa trở nên độc hại hơn, hoạt động sẽ giảm đi.\n",
        "- Sưng bụng (Abdominal Distention): Theo tác giả, đây là một thông số quan trọng. Một động vật có sưng bụng có khả năng đau và giảm động ruột. Một con ngựa có sưng bụng nặng có khả năng cần phẫu thuật chỉ để giảm áp lực.\n",
        "- Ống Nạng Dạ Dày (Nasogastric Tube): Đề cập đến bất kỳ khí nào thoát ra khỏi ống. Một lớp khí lớn trong dạ dày có khả năng gây ra đau rối cho con ngựa.\n",
        "- Trào ngược Dạ Dày (Nasogastric Reflux): Số lượng trào ngược càng lớn, khả năng có một chướng ngại vật nghiêm trọng cho sự chuyển hóa chất lỏng từ phần còn lại của ruột.\n",
        "- Độ pH của trào ngược dạ dày (Nasogastric Reflux pH): Thang từ 0 đến 14 với 7 là trung tính, và giá trị bình thường nằm trong khoảng từ 3 đến 4.\n",
        "Kiểm tra Hậu môn Phân (Rectal Exam Feces): Phân vắng có thể chỉ ra sự tắc nghẽn.\n",
        "- Bụng (Abdomen): Cứng có thể chỉ một tắc nghẽn do tắc nghẽn cơ học và thường được điều trị y tế. Một ruột non căng và một ruột to căng chỉ ra một tổn thương phẫu thuật.\n",
        "- Thể tích Tế bào Đóng gói (Packed Cell Volume): Phạm vi bình thường là từ 30 đến 50. Mức độ tăng lên khi tuần hoàn bị ảnh hưởng hoặc khi động vật trở nên mất nước.\n",
        "- Tổng Protein (Total Protein): Giá trị bình thường nằm trong khoảng từ 6 đến 7.5 gms/dL, và giá trị càng cao thì khả năng mất nước càng lớn.\n",
        "- Diện mạo bụng (Abdomo Appearance): Chất lỏng bình thường là trong suốt trong khi màu sắc hoặc huyết dịch chỉ ra ruột bị ảnh hưởng.\n",
        "- Protein bụng (Abdomo Protein): Càng cao càng có khả năng ruột bị ảnh hưởng. Giá trị nằm trong gms/dL.\n",
        "- Tổn thương Phẫu thuật (Surgical Lesion): Trong quá khứ, vấn đề (tổn thương) có cần phẫu thuật không?\n",
        "- Tổn thương 1, Tổn thương 2, Tổn thương 3 (Lesion 1, Lesion 2, Lesion 3): Loại tổn thương. Số đầu tiên là vị trí tổn thương. Số thứ hai là loại. Số thứ ba là phân loại con. Số thứ tư là mã cụ thể. Thật không may, những chỉ số này có thể là những số có hai chữ số, vì vậy rất khó để diễn giải.\n",
        "- Dữ liệu Cp (Cp Data): Dữ liệu bệnh lý có hiện diện cho trường hợp này không? Biến số này không có ý nghĩa vì dữ liệu bệnh lý không được bao gồm hoặc thu thập cho những trường hợp này.\n",
        "- Kết quả (Outcome): Tình trạng sức khỏe của ngựa. Biến cố để dự đoán."
      ],
      "metadata": {
        "id": "n2fp7lkHjGHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT CÁC THƯ VIỆN"
      ],
      "metadata": {
        "id": "d905_zypEJ-S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXT-dQgNNSFQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from scipy import stats\n",
        "from lightgbm import LGBMClassifier\n",
        "from tabulate import tabulate\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from keras.utils import to_categorical, plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# READ DATA"
      ],
      "metadata": {
        "id": "5oONXBI9Z32l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/test.csv\")\n",
        "pd.set_option( \"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "B8MkSTY5WNg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "aXVXzsOHZ6GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "GvLVVWb9WtvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "tNrpT4NvWw1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info(show_counts=True)"
      ],
      "metadata": {
        "id": "IVVb5P2nYtuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_min_max = [\n",
        "    ['rectal_temp', train_data.rectal_temp.min(), train_data.rectal_temp.max()],\n",
        "    ['pulse', train_data.pulse.min(), train_data.pulse.max()],\n",
        "    ['respiratory_rate', train_data.respiratory_rate.min(), train_data.respiratory_rate.max()],\n",
        "    ['nasogastric_reflux_ph', train_data.nasogastric_reflux_ph.min(), train_data.nasogastric_reflux_ph.max()],\n",
        "    ['packed_cell_volume', train_data.packed_cell_volume.min(), train_data.packed_cell_volume.max()],\n",
        "    ['total_protein', train_data.total_protein.min(), train_data.total_protein.max()],\n",
        "    ['abdomo_protein', train_data.abdomo_protein.min(), train_data.abdomo_protein.max()]\n",
        "]\n",
        "\n",
        "print(\n",
        "    tabulate(\n",
        "        fraud_min_max,\n",
        "        headers=['columns', 'min value', 'max value'],\n",
        "        showindex=True,\n",
        "        tablefmt='github',\n",
        "        numalign='right'\n",
        "    )\n",
        ")\n",
        "train_data.describe()"
      ],
      "metadata": {
        "id": "IxIvu9Jy7UvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.describe()"
      ],
      "metadata": {
        "id": "Zt05_IpV7aZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.isnull().sum()"
      ],
      "metadata": {
        "id": "kjZBcehGXkyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.isnull().sum()"
      ],
      "metadata": {
        "id": "P2fyMgG3Xpw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.duplicated().sum())\n",
        "print(test_data.duplicated().sum())"
      ],
      "metadata": {
        "id": "qjalLk_7Y3cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bộ dữ liệu không có giá trị trùng lặp. Số lượng hàng trùng lặp, được đánh giá bằng cách sử dụng hàm duplicated(), là không. Sự thiếu hụt giá trị trùng lặp này đóng vai trò quan trọng trong việc duy trì tính toàn vẹn và đáng tin cậy của bộ dữ liệu, đảm bảo rằng mỗi bản ghi giao dịch là duy nhất và ngăn chặn bất kỳ biến dạng tiềm ẩn nào trong phân tích do thông tin dư thừa."
      ],
      "metadata": {
        "id": "Vc1AyuImZAbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAIN DATA\")\n",
        "print(train_data.value_counts())\n",
        "print(train_data['outcome'].value_counts())\n",
        "print(\"TEST DATA\")\n",
        "print(test_data.value_counts())"
      ],
      "metadata": {
        "id": "FkawT3-FZZXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRỰC QUAN HÓA DỮ LIỆU ĐƠN BIẾN"
      ],
      "metadata": {
        "id": "vlnLIw88Z9WP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## label distribution"
      ],
      "metadata": {
        "id": "C_XfpxO5ajd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['outcome'].value_counts().plot(kind='pie', legend=train_data['outcome'].value_counts, autopct='%1.1f%%', )\n",
        "plt.show()\n",
        "print(train_data['outcome'].value_counts())"
      ],
      "metadata": {
        "id": "DQRUUfjdaAvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_cat = [column for column in train_data.columns] # Loại bỏ các cột numeric\n",
        "\n",
        "def countplot(dframe, cols, numsofcols, hue):\n",
        "    numsofrows = (len(cols) - 1) // numsofcols + 1\n",
        "    fig, ax = plt.subplots(numsofrows, numsofcols, figsize=(17, 4 * numsofrows))\n",
        "    ax = ax.flatten()\n",
        "\n",
        "    for i, column in enumerate(cols):\n",
        "        sns.countplot(data=dframe, x=column, ax=ax[i], hue=hue)\n",
        "        ax[i].set_title(f'{column} Counts', fontsize=16)\n",
        "        ax[i].set_xlabel(None, fontsize=15)\n",
        "        ax[i].set_ylabel(None, fontsize=15)\n",
        "        ax[i].tick_params(axis='x', rotation=12)\n",
        "\n",
        "        for p in ax[i].patches:\n",
        "            value = int(p.get_height())\n",
        "            ax[i].annotate(f'{value:.0f}', (p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "                           ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        ylim_top = ax[i].get_ylim()[1]\n",
        "        ax[i].set_ylim(top=ylim_top * 1.1)\n",
        "\n",
        "    # Tắt các ô trống trong lưới biểu đồ\n",
        "    for j in range(i + 1, len(ax)):\n",
        "        ax[j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Gọi hàm với các tham số phù hợp\n",
        "countplot(train_data, columns_cat, numsofcols=3, hue='outcome')"
      ],
      "metadata": {
        "id": "yZnUGeprj1yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nếu con ngựa được phẫu thuật, có khả năng cao hơn là chết.\n",
        "- Ngựa trẻ có nhiều cơ hội hơn để chết.\n",
        "- Nếu Temp_Of_Extremities là ấm hoặc bình thường, con ngựa có khả năng sống cao hơn.\n",
        "- Nếu Peripheral_Pulse là bình thường hoặc tăng, con ngựa có khả năng sống cao hơn. Ngược lại, vắng mặt có nghĩa là có khả năng cao hơn là phải tiêu huỷ.\n",
        "- Nếu Mucous_Membrane là hồng nhạt, hồng sáng hoặc hồng bình thường, con ngựa có khả năng sống cao hơn.\n",
        "- Nếu Capillary_Refill_Time là dưới 3 giây, con ngựa có khả năng sống cao hơn.\n",
        "- Đau nhẹ hoặc tỉnh táo trong Pain giúp con ngựa có khả năng sống cao hơn.\n",
        "- Bình thường, chuyển động quá mức hoặc chuyển động thấp trong Peristalsis giúp con ngựa có khả năng sống cao hơn.\n",
        "- Nhẹ hoặc không trong Abdominal_Distention giúp con ngựa có khả năng sống cao hơn.\n",
        "- Khi Nasogastric_Tube là nhẹ, có hơn $50$% khả năng con ngựa sống. Trong các phân loại còn lại, tình hình hỗn loạn.\n",
        "- Khi Nasogastric_Reflux là nhẹ hoặc không, có một khả năng lớn là con ngựa sẽ sống.\n",
        "- Khi Rectal_Exam_Feces là vắng mặt, có khả năng cao hơn là con ngựa sẽ chết.\n",
        "- Khi Abdomen là cứng hoặc khác, có khả năng cao hơn là con ngựa sẽ sống.\n",
        "- Trong trường hợp của Abdomo_Appearance, không có có nghĩa là con ngựa có khả năng cao hơn bị tiêu huỷ. Ngược lại, rõ ràng giúp con ngựa có khả năng sống cao hơn.\n",
        "- Nếu vấn đề (tổn thương) là phẫu thuật, thì con ngựa có khả năng cao hơn chết.\n",
        "- Nếu dữ liệu bệnh lý có mặt, có khả năng cao hơn là bị tiêu huỷ khi vẫn còn sống."
      ],
      "metadata": {
        "id": "Z9UM6kCDUnyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Có ba loại kết quả là sống, chết và bị thiến. Như chúng ta có thể thấy, số lượng ngựa chết và bị thiến gần như tương đương và cao trong các trường hợp ngay cả khi đã thực hiện phẫu thuật so với không thực hiện phẫu thuật.\n",
        "- Số lượng ngựa trưởng thành nhiều hơn số lượng ngựa non, do đó, kết quả cũng tỷ lệ thuận với độ tuổi của chúng.\n",
        "- Tỷ lệ tử vong của ngựa non cao hơn như chúng ta có thể quan sát từ các biểu đồ.\n",
        "- Chúng ta cũng có thể quan sát kết quả của ngựa ở các nhiệt độ khác nhau. Như chúng ta có thể thấy, có nhiều ngựa sống sót hơn ở nhiệt độ bình thường và mát mẻ, nhưng ở nhiệt độ mát mẻ, có nhiều ngựa chết hơn.\n",
        "- Chúng ta cũng có thể quan sát rằng khi nhịp tim bình thường và giảm, số lượng ngựa và tỷ lệ sống và chết của chúng gần như tương đương và cao trong các trường hợp nhịp tim giảm và ít hơn trong các trường hợp tử vong ở nhịp tim bình thường.\n",
        "- Tương tự, có nhiều đặc điểm khác ảnh hưởng đến việc dự đoán tình trạng sức khỏe của ngựa, như bạn có thể thấy trong các biểu đồ dưới đây."
      ],
      "metadata": {
        "id": "DB7yUwhnlQXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('seaborn-darkgrid')\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train_data['pulse'], kde=True, color='blue', bins=20)\n",
        "plt.title('Distribution of Pulse')\n",
        "plt.xlabel('Pulse')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Vk6g7ae7s1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['surgery', 'age', 'temp_of_extremities', 'pain']\n",
        "plt.figure(figsize=(12, 10))\n",
        "for i, col in enumerate(categorical_cols, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.countplot(x=col, data=train_data, palette='viridis')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nzPg6OjC7y7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = ['rectal_temp', 'pulse', 'respiratory_rate']\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(1, 3, i)\n",
        "    plt.hist(train_data[col], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tKGRadXl7359"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='rectal_temp', y='pulse', data=train_data, hue='pain', palette='muted', alpha=0.8)\n",
        "plt.title('Relationship between Rectal Temperature and Pulse')\n",
        "plt.xlabel('Rectal Temperature')\n",
        "plt.ylabel('Pulse')\n",
        "plt.legend(title='Pain')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EKsphWOq787f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRỰC QUAN OUTLIER"
      ],
      "metadata": {
        "id": "Njz6-LaNE21K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = ['rectal_temp', 'pulse', 'respiratory_rate', 'packed_cell_volume', 'total_protein', 'abdomo_protein']\n",
        "train_data[numeric_columns] = train_data[numeric_columns].apply(pd.to_numeric, errors='coerce')"
      ],
      "metadata": {
        "id": "rOPgIxXkE6lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dùng biểu đồ Boxplot để trực quan hóa các giá trị ngoại lai.\n"
      ],
      "metadata": {
        "id": "H-7KgeVZNG9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in numeric_columns:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.boxplot(x=train_data[column])\n",
        "    plt.title(f'Box plot for {column}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "duL2PXm5M99s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tính toán Z-score cho từng cột số học và xác định các giá trị vượt quá ngưỡng (thường là > 3 hoặc < -3). để xác định outliers"
      ],
      "metadata": {
        "id": "i39gLJPyNLgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in numeric_columns:\n",
        "    z_scores = np.abs(stats.zscore(train_data[column].dropna()))\n",
        "    outliers = train_data[z_scores > 3]\n",
        "    print(f\"Outliers in {column} using Z-score:\\n\", outliers)\n"
      ],
      "metadata": {
        "id": "8Iw0mTfSNPE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tính toán IQR cho từng cột số học và xác định các giá trị nằm ngoài khoảng Q1 - 1.5 * IQR đến Q3 + 1.5 * IQR."
      ],
      "metadata": {
        "id": "pM0ufh52NhSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in numeric_columns:\n",
        "    Q1 = train_data[column].quantile(0.25)\n",
        "    Q3 = train_data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = train_data[(train_data[column] < lower_bound) | (train_data[column] > upper_bound)]\n",
        "    print(f\"Outliers in {column} using IQR:\\n\", outliers)\n"
      ],
      "metadata": {
        "id": "1zH3ncSwNgXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in numeric_columns:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.scatter(range(train_data.shape[0]), np.log1p(train_data[column]), alpha=0.5)\n",
        "    plt.title(f'Scatter plot for log-transformed {column}')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel(f'Log-transformed {column}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "9WJ3DCZONvaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRỰC QUAN HÓA DỮ LIỆU ĐA BIẾN"
      ],
      "metadata": {
        "id": "eqZRNJ2rFBkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ĐỘ TƯƠNG QUAN GIỮA CÁC FEATURE"
      ],
      "metadata": {
        "id": "q7pWZWaVFFep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "numerical_features\n",
        "\n",
        "plt.figure(figsize=(9, 5))\n",
        "correlation_matrix = train_data[numerical_features].corr().round(2)\n",
        "\n",
        "sns.heatmap(data=correlation_matrix, annot=True, cmap='BuPu', linewidths=0.5)\n",
        "plt.title('Correlation Matrix for Numerical Features', size=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gVTFzxPTFDAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLEAN DATA PREPROCESS"
      ],
      "metadata": {
        "id": "lPqVD3m6XJ3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data[train_data.columns[1:]] # Remove id in Data table\n",
        "test_data = test_data[test_data.columns[1:]] # Remove id in Data table"
      ],
      "metadata": {
        "id": "bdICWIdPXJLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_missing_cols = train_data.columns[train_data.isnull().any()]\n",
        "test_missing_cols = test_data.columns[test_data.isnull().any()]\n",
        "\n",
        "train_missing_cols = list(train_missing_cols)\n",
        "test_missing_cols = list(test_missing_cols)\n",
        "\n",
        "def replace_missing_with_most_common(data, columns):\n",
        "    for column in columns:\n",
        "        col_most_common = data[column].value_counts().index[0]\n",
        "        data[column] = data[column].replace({np.nan: col_most_common})\n",
        "    return data\n",
        "\n",
        "train = replace_missing_with_most_common(train_data, train_missing_cols)\n",
        "test = replace_missing_with_most_common(test_data,test_missing_cols)"
      ],
      "metadata": {
        "id": "dFsHeNiy-Evt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_train = train.select_dtypes(include=['float'])\n",
        "Classify_train = train.select_dtypes(exclude = ['float'])\n",
        "\n",
        "numeric_test = test.select_dtypes(include =('float'))\n",
        "Classify_test = test.select_dtypes(exclude = ['float'])"
      ],
      "metadata": {
        "id": "NmBkOjdvYLRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Classify_train[Classify_train.columns[1:]].nunique()\n",
        "Classify_test[Classify_test.columns[1:]].nunique()"
      ],
      "metadata": {
        "id": "5wf6bextYOXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Classify_train = Classify_train.fillna(\"unknown\")\n",
        "Classify_test = Classify_test.fillna(\"unknown\")"
      ],
      "metadata": {
        "id": "BGWU_PpYYSmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_train.head()"
      ],
      "metadata": {
        "id": "NEQ3dNOuim-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Classify_train"
      ],
      "metadata": {
        "id": "b0N1pYP1ipLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "category_variables=['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse','mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n",
        "       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux','rectal_exam_feces','abdomen', 'abdomo_appearance', 'surgical_lesion','cp_data', 'outcome']\n",
        "animal_encoder=LabelEncoder()\n",
        "for category in category_variables:\n",
        "    Classify_train[category]=animal_encoder.fit_transform(Classify_train[category])\n",
        "Classify_train\n",
        "for category in category_variables:\n",
        "    if(category == 'outcome'):\n",
        "      continue\n",
        "    Classify_test[category]=animal_encoder.fit_transform(Classify_test[category])\n",
        "Classify_test"
      ],
      "metadata": {
        "id": "5B_fB_xzqMNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_ot_train = pd.concat([numeric_train, Classify_train[Classify_train.columns]],axis = 1)\n",
        "numeric_ot_train"
      ],
      "metadata": {
        "id": "yt7dJgba8sCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_ot_test = pd.concat([numeric_test, Classify_test[Classify_test.columns]],axis = 1)\n",
        "numeric_ot_test"
      ],
      "metadata": {
        "id": "U0pPw4yBvyir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = numeric_ot_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "numerical_features\n",
        "\n",
        "plt.figure(figsize=(13, 13))\n",
        "correlation_matrix = numeric_ot_train[numerical_features].corr().round(2)\n",
        "\n",
        "sns.heatmap(data=correlation_matrix, annot=True, cmap='BuPu', linewidths=0.5)\n",
        "plt.title('Correlation Matrix for Numerical Features', size=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DbtkekgmPw-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cdtcJEFsER3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XỬ LÝ OUTLIER"
      ],
      "metadata": {
        "id": "3tw55JPVFQHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import iqr\n",
        "numeric_columns = ['rectal_temp', 'pulse', 'respiratory_rate', 'packed_cell_volume', 'total_protein', 'abdomo_protein']\n",
        "for column in numeric_columns:\n",
        "    column_data = numeric_ot_train[column]\n",
        "    column_iqr = iqr(column_data)\n",
        "    print(f\"IQR for {column}: {column_iqr}\")"
      ],
      "metadata": {
        "id": "QWfxJvxvFVNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Áp dụng Robust Scaling cho các cột số trong numeric_columns. Robust Scaling là một phương pháp chuẩn hóa dữ liệu dựa trên median và IQR, giúp giảm ảnh hưởng của outliers."
      ],
      "metadata": {
        "id": "CJYI2F4D_NCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import  RobustScaler\n",
        "\n",
        "def handleOutliner(data):\n",
        "  for column in numeric_columns:\n",
        "      data[column] = np.log1p(data[column])\n",
        "\n",
        "  robust_scaler = RobustScaler()\n",
        "  data[numeric_columns] = robust_scaler.fit_transform(data[numeric_columns])\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "numeric_ot_train = handleOutliner(numeric_ot_train)\n",
        "numeric_ot_test = handleOutliner(numeric_ot_test)\n",
        "numeric_ot_train"
      ],
      "metadata": {
        "id": "DYBKu0oB_Li5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Imbalance"
      ],
      "metadata": {
        "id": "gG3wqLJa_vKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4),dpi=100)\n",
        "\n",
        "ax= sns.countplot(data=numeric_ot_train, x='outcome')\n",
        "ax.bar_label(ax.containers[0], fmt='%.1f')\n",
        "plt.xticks([0,1,2], ['died', 'euthanized', 'lived'])\n",
        "plt.xlabel(\"Before Balancing\")"
      ],
      "metadata": {
        "id": "AYArOAIO_xrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = numeric_ot_train.drop(['outcome'], axis=1)\n",
        "y = numeric_ot_train['outcome']\n",
        "y"
      ],
      "metadata": {
        "id": "JwYliZBZAAAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mục đích của việc sử dụng SMOTE ở đây là tạo thêm các ví dụ tổng hợp về lớp thiểu số  trong dữ liệu huấn luyện. Điều này giúp mô hình không bị thiên vị về nhóm đa số trong quá trình đào tạo, cải thiện khả năng phát hiện các mẫu gian lận.\n",
        "- Sử dụng SMOTE(Kỹ thuật lấy mẫu quá mức thiểu số tổng hợp) để cân bằng tập dữ liệu. Số lượng kết quả cho thấy hiện tại chúng tôi có số lượng phiên bản lớp chính xác (1 và 0)."
      ],
      "metadata": {
        "id": "pVYIEFE1Aykl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "smoteomek=SMOTETomek(sampling_strategy='all')\n",
        "X_over,y_over =smoteomek.fit_resample(X,y)"
      ],
      "metadata": {
        "id": "ZOSJAr7r_5Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4),dpi=100)\n",
        "\n",
        "ax= sns.countplot(data=train, x=y_over)\n",
        "ax.bar_label(ax.containers[0], fmt='%.1f')\n",
        "plt.xticks([0,1,2], ['died', 'euthanized', 'lived'])\n",
        "plt.xlabel(\"After Balancing\")"
      ],
      "metadata": {
        "id": "M8Gl-wBFA6WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature scaling"
      ],
      "metadata": {
        "id": "1UUyS71zFZQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- chuẩn hóa hoặc chuẩn hóa phạm vi của các biến hoặc tính năng độc lập trong tập dữ liệu\n",
        "- Mục tiêu chính của việc chia tỷ lệ đối tượng là đưa tất cả các đối tượng về một tỷ lệ tương tự mà không làm sai lệch sự khác biệt trong phạm vi giá trị"
      ],
      "metadata": {
        "id": "Gaxbq_jnl45f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler= StandardScaler()\n",
        "scaler.fit(X_over)\n",
        "X_train = scaler.transform(X_over)\n",
        "Y_train = y_over\n",
        "\n",
        "#  cho dữ liệu test\n",
        "scaler.fit(numeric_ot_test)\n",
        "X_test_numeric_ot_test = scaler.transform(numeric_ot_test)"
      ],
      "metadata": {
        "id": "I2opaFHWFbKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since we're dealing with decision trees we must be very careful with the missing data\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Máy tính đơn biến để hoàn thành các giá trị còn thiếu bằng các chiến lược simple strategies.\n",
        "# Thay thế các giá trị bị thiếu bằng cách sử dụng thống kê mô tả (ví dụ: trung bình, trung vị hoặc thường xuyên nhất) dọc theo mỗi cột hoặc sử dụng giá trị không đổi.\n",
        "import numpy as np\n",
        "\n",
        "imp=SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\")\n",
        "X_train=imp.fit_transform(X_train)\n",
        "X_test_numeric_ot_test=imp.fit_transform(X_test_numeric_ot_test)"
      ],
      "metadata": {
        "id": "jqMYUwxaGSHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINNING"
      ],
      "metadata": {
        "id": "5mkdvs87Fbni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, f1_score, roc_auc_score, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "28IRzAUMb0uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.3, random_state = 1)\n",
        "\n",
        "print(\"Shape of x_train: \", x_train.shape)\n",
        "print(\"Shape of x_test: \", x_test.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)"
      ],
      "metadata": {
        "id": "QH8adGcnCuPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "gu6wLKkZbucR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrices using heatmap with a different colormap\n",
        "def visualization_confusion_matrix(matrix, name):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
        "    plt.title(name)\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "NPVYdj6U26-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "IZK9d9fTF2iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_DT = DecisionTreeClassifier()\n",
        "model_DT.fit(x_train, y_train)\n",
        "y_pred = model_DT.predict(x_test)\n",
        "\n",
        "DT_new_training = model_DT.score(x_train, y_train)\n",
        "DT_new_test = model_DT.score(x_test, y_test)\n",
        "\n",
        "print(\"Độ chính xác về dữ liệu đào tạo : \", DT_new_training)\n",
        "print(\"Điểm chính xác trên Dữ liệu thử nghiệm :  \", DT_new_test)\n",
        "\n",
        "reportdt = classification_report(y_test, y_pred)\n",
        "dt_cm_new=confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(dt_cm_new)\n",
        "print(reportdt)\n",
        "\n",
        "visualization_confusion_matrix(dt_cm_new,'Random Forest Classifier' )"
      ],
      "metadata": {
        "id": "iG8ZRtO7F0tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Source\n",
        "from sklearn.tree import export_graphviz\n",
        "import os as os\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"decision_trees\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "export_graphviz(\n",
        "        model_DT,\n",
        "        out_file=os.path.join(IMAGES_PATH, \"tree.dot\"),\n",
        "        feature_names=['surgery', 'age', 'hospital_number', 'rectal_temp', 'pulse',\n",
        "       'respiratory_rate', 'temp_of_extremities', 'peripheral_pulse',\n",
        "       'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n",
        "       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux',\n",
        "       'nasogastric_reflux_ph', 'rectal_exam_feces', 'abdomen',\n",
        "       'packed_cell_volume', 'total_protein', 'abdomo_appearance',\n",
        "       'abdomo_protein', 'surgical_lesion', 'lesion_1', 'lesion_2', 'lesion_3',\n",
        "       'cp_data'],\n",
        "        rounded=True,\n",
        "        filled=True\n",
        "    )"
      ],
      "metadata": {
        "id": "lA6dq9q_I1v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Source.from_file(os.path.join(IMAGES_PATH, \"tree.dot\"))"
      ],
      "metadata": {
        "id": "nv8JKehJI3ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 0 - died\n",
        "- 1 - authanized\n",
        "-  2 - live"
      ],
      "metadata": {
        "id": "Bv-HuCesztoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### naive bayes"
      ],
      "metadata": {
        "id": "yBiueqWWF1CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train different NB classifiers\n",
        "nb_classifiers = {\n",
        "    'GaussianNB': GaussianNB(),\n",
        "    'BernoulliNB': BernoulliNB()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for clf_name, clf in nb_classifiers.items():\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')  # Change to 'micro', 'macro', or 'weighted'\n",
        "    recall = recall_score(y_test, y_pred, average='macro')        # Change to 'micro', 'macro', or 'weighted'\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Store the results\n",
        "    results[clf_name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Classification Report': classification_report(y_test, y_pred),\n",
        "        'Confusion Matrix': visualization_confusion_matrix(confusion_matrix(y_test, y_pred), clf_name)\n",
        "    }\n",
        "\n",
        "# Print the results\n",
        "for config_name, metrics in results.items():\n",
        "    print(f\"{config_name} Metrics:\")\n",
        "    for metric, value in metrics.items():\n",
        "        if metric in ['Classification Report', 'Confusion Matrix']:\n",
        "            print(f\"{metric}:\\n{value}\\n\")\n",
        "        else:\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "nJOF78xHF7q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 0 - died\n",
        "- 1 - authanized\n",
        "-  2 - live"
      ],
      "metadata": {
        "id": "KUARjxto4IVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "3hVvQ5uGF75i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5,p=1)\n",
        "knn.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "knn_new_training = knn.score(x_train, y_train)\n",
        "knn_new_test = knn.score(x_test, y_test)\n",
        "print(\"Độ chính xác về dữ liệu đào tạo : \", knn_new_training)\n",
        "print(\"Điểm chính xác trên Dữ liệu thử nghiệm :  \", knn_new_test)\n",
        "\n",
        "y_pred = knn.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "knn_cm_new=confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(report)\n",
        "\n",
        "visualization_confusion_matrix(knn_cm_new, \"KNN\")"
      ],
      "metadata": {
        "id": "M1HVbm4DGA0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Means"
      ],
      "metadata": {
        "id": "OQMcBgmgGBGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score, confusion_matrix\n",
        "\n",
        "# Initialize K-means with different numbers of clusters\n",
        "kmeans_configs = {\n",
        "    'KMeans_3': KMeans(n_clusters=3, random_state=42),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for config_name, kmeans in kmeans_configs.items():\n",
        "    kmeans.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = kmeans.predict(x_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    ari = adjusted_rand_score(y_test, y_pred)\n",
        "    nmi = normalized_mutual_info_score(y_test, y_pred)\n",
        "    silhouette = silhouette_score(x_test, y_pred)\n",
        "\n",
        "    # Calculate traditional classification metrics (for reference)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Calculate classification report and confusion matrix\n",
        "    class_report = classification_report(y_test, y_pred, zero_division=0)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[config_name] = {\n",
        "        'Adjusted Rand Index': ari,\n",
        "        'Normalized Mutual Information': nmi,\n",
        "        'Silhouette Score': silhouette,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Classification Report': class_report,\n",
        "        'Confusion Matrix':  visualization_confusion_matrix(conf_matrix, config_name)\n",
        "    }\n",
        "\n",
        "# Print the results\n",
        "for config_name, metrics in results.items():\n",
        "    print(f\"{config_name} Metrics:\")\n",
        "    for metric, value in metrics.items():\n",
        "        if metric in ['Classification Report', 'Confusion Matrix']:\n",
        "            print(f\"{metric}:\\n{value}\\n\")\n",
        "        else:\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "-IKk3BP3GKeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classifier"
      ],
      "metadata": {
        "id": "ujeTLxMUGXvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf = RandomForestClassifier(n_estimators=100,max_depth=8,random_state=42,\n",
        "                                verbose=1,class_weight=\"balanced\")\n",
        "\n",
        "rf_clf.fit(x_train,y_train)\n",
        "\n",
        "# Calculate training and test accuracy\n",
        "RF_new_training = rf_clf.score(x_train, y_train)\n",
        "RF_new_test = rf_clf.score(x_test, y_test)\n",
        "\n",
        "print(\"Độ chính xác về dữ liệu đào tạo : \", RF_new_training)\n",
        "print(\"Điểm chính xác trên Dữ liệu thử nghiệm :  \", RF_new_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred = rf_clf.predict(x_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "confusion_randomtree = confusion_matrix(y_test,y_pred)\n",
        "print(\"Báo cáo phân loại cho phân loại rừng ngẫu nhiên: \\n\", classification_report(y_test, y_pred))\n",
        "print(\"Ma trận nhầm lẫn của phân loại rừng ngẫu nhiên: \\n\", confusion_randomtree)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20,5))\n",
        "ax[0].set_title('Confusion Matrix of Random Forest Model:')\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, colorbar=False, values_format='', cmap='crest', ax=ax[0])\n",
        "ax[0].grid(False)"
      ],
      "metadata": {
        "id": "r5oHsxTDGZEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling using Xg-Boost (eXtreme Gradient Boosting) gradient boosting."
      ],
      "metadata": {
        "id": "czIleTtcINeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "model_XGB = XGBClassifier(\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=400,\n",
        "    objective=\"binary:hinge\",\n",
        "    booster='gbtree',\n",
        "    scale_pos_weight=1,\n",
        "    base_score=0.5,\n",
        "    random_state=42,\n",
        "    verbosity=1  # Sửa giá trị thành một số nguyên (ví dụ: 0, 1, 2)\n",
        ")\n",
        "\n",
        "model_XGB.fit(x_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "oHJsCYz_IPwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_new_training = model_XGB.score(x_train, y_train)\n",
        "XGB_new_test = model_XGB.score(x_test, y_test)\n",
        "\n",
        "\n",
        "print(\"Độ chính xác về dữ liệu đào tạo: \", XGB_new_training)\n",
        "print(\"Điểm chính xác trên Dữ liệu thử nghiệm: \", XGB_new_test)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = model_XGB.predict(x_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "\n",
        "confusion_xgb = confusion_matrix(y_test,y_pred)\n",
        "print(\"Báo cáo phân loại : \\n\", classification_report(y_test, y_pred))\n",
        "print(\"Ma trận nhầm lẫn  \\n\", confusion_xgb)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20,5))\n",
        "ax[0].set_title('Confusion Matrix of Random Forest Model:')\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, colorbar=False, values_format='', cmap='crest', ax=ax[0])\n",
        "ax[0].grid(False)"
      ],
      "metadata": {
        "id": "xvKfPV0Mf2L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed Forward Neural Network"
      ],
      "metadata": {
        "id": "WeLL029oIQ1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "rNupzcB8f53Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model_FFNN = Sequential()\n",
        "\n",
        "# Add the input layer and the first hidden layer\n",
        "model_FFNN.add(Dense(32, input_shape=(27,), activation='relu'))\n",
        "\n",
        "# Add another hidden layer\n",
        "model_FFNN.add(Dense(units=32, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_FFNN.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_FFNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_FFNN.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "dazK1Mh-IT_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá mô hình trên tập kiểm thử\n",
        "loss, accuracy = model_FFNN.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Dự đoán và đánh giá precision, recall, và f1-score\n",
        "\n",
        "y_pred = model_FFNN.predict(x_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "visualization_confusion_matrix(conf_matrix,\"FNN\")"
      ],
      "metadata": {
        "id": "36UqTU-af-1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recurrent Neural Network"
      ],
      "metadata": {
        "id": "7YMXgwG0IUHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM, Input, Dropout\n",
        "from keras import backend as K, regularizers, Model, metrics"
      ],
      "metadata": {
        "id": "pFb6uUQxIYgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# design network\n",
        "np.random.seed(7)\n",
        "\n",
        "# X_train et X_val sont des dataframe qui contient les features\n",
        "train_LSTM_X=x_train\n",
        "val_LSTM_X=x_test\n",
        "\n",
        "## Reshape input to be 3D [samples, timesteps, features] (format requis par LSTM)\n",
        "train_LSTM_X = train_LSTM_X.reshape((train_LSTM_X.shape[0], 1, train_LSTM_X.shape[1]))\n",
        "val_LSTM_X = val_LSTM_X.reshape((val_LSTM_X.shape[0], 1, val_LSTM_X.shape[1]))\n",
        "\n",
        "## Recuperation des labels\n",
        "train_LSTM_y=y_train\n",
        "val_LSTM_y=y_test"
      ],
      "metadata": {
        "id": "7KQXkDJ6gT0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input((1, 27))\n",
        "x1 = LSTM(50, dropout=0.3, recurrent_dropout=0.2, return_sequences=True)(inputs)\n",
        "x2 = LSTM(50, dropout=0.3, recurrent_dropout=0.2)(x1)\n",
        "outputs = Dense(1, activation='sigmoid')(x2)\n",
        "model = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "piiJL4FWgWsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nmqSgGkegY3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_LSTM_X, train_LSTM_y,epochs=20,batch_size=32, validation_data=(val_LSTM_X, val_LSTM_y))"
      ],
      "metadata": {
        "id": "SlSGBkqxgbD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_DL = pd.DataFrame(history.history)\n",
        "df_DL.head()\n",
        "plt.plot(df_DL.index, df_DL['loss'], label = 'loss')\n",
        "plt.plot(df_DL.index, df_DL['val_loss'], label = 'Val_loss')\n",
        "plt.xlabel( 'Epochs')\n",
        "plt.ylabel('crossentropy')\n",
        "plt.title('DL loss function')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "inR4YJ3Ze6d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(val_LSTM_X)\n",
        "y_pred = np.argmax(y_pred, axis = 1) # Inverse to_categorical\n",
        "print(classification_report(val_LSTM_y, y_pred))"
      ],
      "metadata": {
        "id": "KLHNrMk_fISB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OVERFITTING"
      ],
      "metadata": {
        "id": "CDs66_WOIjbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using StratifiedKFold for cross-validation."
      ],
      "metadata": {
        "id": "dfFIhaOmImGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "X = X_over\n",
        "\n",
        "y = Y_train\n",
        "\n",
        "\n",
        "# Stratified train-test split\n",
        "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "for train_idx, test_idx in skfold.split(X,y):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "scaled_train = sc.fit_transform(X_train)\n",
        "scaled_test = sc.transform(X_test)\n",
        "X_train = pd.DataFrame(scaled_train, index=X_train.index, columns=X_train.columns)\n",
        "X_test = pd.DataFrame(scaled_test, index=X_test.index, columns=X_test.columns)\n",
        "\n",
        "\n",
        "X_train_, y_train_ = RandomUnderSampler(sampling_strategy='majority').fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "L8bVtTGkIoTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_"
      ],
      "metadata": {
        "id": "knp-mDGbZMXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_"
      ],
      "metadata": {
        "id": "ISKz-9FAZPen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_comparison_evaluate(classifiers, X, y):\n",
        "    print('K-Fold Cross-Validation:\\n')\n",
        "    for name, model in classifiers.items():\n",
        "        print('{}:'.format(name))\n",
        "\n",
        "        scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "\n",
        "        for score in scoring:\n",
        "            scores = cross_val_score(model, X, y, scoring=score, cv=skfold, n_jobs=-1)\n",
        "            print('Mean {} score: {:.3f} ({:.3f})'.format(score, scores.mean(), scores.std()))\n",
        "\n",
        "        print('\\n')"
      ],
      "metadata": {
        "id": "oIPKpZAtZS0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    'Random Forest Classifier': RandomForestClassifier(class_weight='balanced', random_state=seed),\n",
        "    'Decision Tree Classifier': DecisionTreeClassifier(class_weight='balanced', random_state=seed),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Feed Forward Neural Network': MLPClassifier(hidden_layer_sizes=(64, 32),\n",
        "                                                activation='relu',\n",
        "                                                solver='adam',\n",
        "                                                max_iter=1000,\n",
        "                                                random_state=seed),\n",
        "    'K-Means': KMeans(n_clusters=3, random_state=seed)  # Adjust n_clusters as needed\n",
        "}"
      ],
      "metadata": {
        "id": "lyLFRsgyZVKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comparison_evaluate(classifiers, X_train_, y_train_)"
      ],
      "metadata": {
        "id": "MUvrTeLlZi9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_.shape\n",
        "y_train_.shape"
      ],
      "metadata": {
        "id": "I5mkAmp0bdTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CẢI THIỆN MÔ HÌNH"
      ],
      "metadata": {
        "id": "Zh1JRIq0JQva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### - Kiểm tra lại các hyperparameters như learning rate, số lượng epochs, kích thước batch, và các hyperparameters khác để xem liệu có thể tối ưu hóa chúng để cải thiện hiệu suất không.thử nghiệm nhiều giá trị khác nhau cho các hyperparameters và chọn những giá trị làm cho mô hình hoạt động tốt nhất trên tập validation hoặc test."
      ],
      "metadata": {
        "id": "eJeDICVwJRvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best hyperparameters using RandomizedSearchCV"
      ],
      "metadata": {
        "id": "bQUPbijBJVlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "1ciXx4trJjnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape\n",
        "Y_train.shape"
      ],
      "metadata": {
        "id": "0IpscrkLbUoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define the hyperparameter grid for Decision Tree\n",
        "param_dist_dt = {\n",
        "    'max_depth': randint(1, 20),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 20),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Create a DecisionTreeClassifier model\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "random_search_dt = RandomizedSearchCV(\n",
        "    dt,\n",
        "    param_distributions=param_dist_dt,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the data\n",
        "random_search_dt.fit(X_train_, y_train_)\n",
        "print('DecisionTreeClassifier Classifier Training Score: {}'.format(random_search_dt.score(X_train_, y_train_)))\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters for DecisionTreeClassifier:\", random_search_dt.best_params_)\n",
        "# Using the best DecisionTreeClassifier model from RandomizedSearchCV\n",
        "best_dt = random_search_dt.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_dt = best_dt.predict(X_test)\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "print(\"\\nConfusion Matrix for DecisionTreeClassifier:\")\n",
        "print(conf_matrix_dt)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "id": "RyJaMzWiJkPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### improve ensemble learning model RandomForestClassifier"
      ],
      "metadata": {
        "id": "1QleGp3ZJuDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define the hyperparameter grid for RandomForestClassifier\n",
        "param_dist_rf = {\n",
        "    'n_estimators': randint(10, 200),\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': randint(1, 20),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 20),\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Create a RandomForestClassifier model\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "random_search_rf = RandomizedSearchCV(\n",
        "    rf,\n",
        "    param_distributions=param_dist_rf,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the data\n",
        "random_search_rf.fit(X_train_, y_train_)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters for RandomForestClassifier:\", random_search_rf.best_params_)\n",
        "best_rf = random_search_rf.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "print('Random Forest Classifier Training Score: {}'.format(random_search_rf.score(X_train_, y_train_)))\n",
        "\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"\\nConfusion Matrix for RandomForestClassifier:\")\n",
        "print(conf_matrix_rf)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "bUzqrFvAJwAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling using Xg-Boost"
      ],
      "metadata": {
        "id": "8GRwpjH_Jy83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define the hyperparameter grid for XGBoost\n",
        "param_dist_xgb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
        "    'min_child_weight': [1, 2, 3, 4],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'gamma': [0, 1, 2, 3]\n",
        "}\n",
        "\n",
        "# Create an XGBoost model\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "random_search_xgb = RandomizedSearchCV(\n",
        "    xgb_model,\n",
        "    param_distributions=param_dist_xgb,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the data\n",
        "random_search_xgb.fit(X_train_, y_train_)\n",
        "print('XGBoost Training Score: {}'.format(random_search_xgb.score(X_train_, y_train_)))\n",
        "# Print the best hyperparameters for XGBoost\n",
        "print(\"Best Hyperparameters for XGBoost:\", random_search_xgb.best_params_)\n",
        "\n",
        "# Using the best XGBoost model from RandomizedSearchCV\n",
        "best_xgb_model = random_search_xgb.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Print the confusion matrix for XGBoost\n",
        "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(\"\\nConfusion Matrix for XGBoost:\")\n",
        "print(conf_matrix_xgb)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "K4KpSPwvJzq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST LẠI VỚI DATA TEST"
      ],
      "metadata": {
        "id": "bVharQW1gIaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Predict = knn.predict(numeric_ot_test)\n",
        "y_predict = pd.Series(Predict)\n",
        "y_predict = y_predict.map({0:'died',1:'euthanized',2:'lived'})\n",
        "y_predict = y_predict.to_list()\n",
        "y_predict"
      ],
      "metadata": {
        "id": "PrthvncFgG9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'y_predict' to a DataFrame\n",
        "df = pd.DataFrame({'outcome': y_predict})\n",
        "numeric_ot_test\n",
        "# Save the DataFrame to a CSV file named 'outcome.csv'\n",
        "df.to_csv('outcome.csv', index=False)"
      ],
      "metadata": {
        "id": "g8uVfRcAJoM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_ot_test"
      ],
      "metadata": {
        "id": "evAatWCCMZkd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}